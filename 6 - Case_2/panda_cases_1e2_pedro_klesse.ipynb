{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d3ec47",
   "metadata": {},
   "source": [
    "# **PANDA - Final Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1d91a",
   "metadata": {},
   "source": [
    "## Author: Pedro Malandrin Klesse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef569c",
   "metadata": {},
   "source": [
    "## Access to the Dataset\n",
    "\n",
    "- https://www.kaggle.com/datasets/muhammadshahidazeem/customer-churn-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fd7837",
   "metadata": {},
   "source": [
    "## Atributes\n",
    "\n",
    "- **CustomerID**: Customer Identification\n",
    "- **Age**: Customer age\n",
    "- **Gender**: Customer Gender (Male or Female)\n",
    "- **Tenure**: Period of time that the person was a company customer\n",
    "- **Usage Frequency**: Frequency of company services usage by the client\n",
    "- **Support Calls**: Number os support calls that the customer requested\n",
    "- **Payment Delay**: Time that the customer delays to pay the service bill after the deadline\n",
    "- **Subscription Type**: Service Type that the customer subscribed (Standand, Basic or Premium)\n",
    "- **Contract Length**: Literally the contract length (Monthly, Quarterly or Annual)\n",
    "- **Total Spend**: Total spend by the customer with company services\n",
    "- **Last Interaction**: Time of the last interaction by the customer with the company\n",
    "- **Churn**: If the customer churn or not (1 ou 0, respectively)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731e010",
   "metadata": {},
   "source": [
    "## PART 1: *Exploratory Data Analysis and Training Machine Learning Models - Customer Churn Dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fda9a4",
   "metadata": {},
   "source": [
    "## Libraries and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import Image\n",
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38642fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('customer_churn_dataset-training-master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c88e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Contract Length'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eae0c9",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140feb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00109c68",
   "metadata": {},
   "source": [
    "## Dataset Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66bc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Linhas: {dataframe.shape[0]}')\n",
    "print(f'Colunas: {dataframe.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c98ecb",
   "metadata": {},
   "source": [
    "## Types of Data and Non-null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ffd991",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5423235",
   "metadata": {},
   "source": [
    "## Verifying Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f604a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c892e8",
   "metadata": {},
   "source": [
    "## Removing Tuples with Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0fc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.dropna()\n",
    "dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f10ef9",
   "metadata": {},
   "source": [
    "## Statistical Resume about the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55781b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc30c5",
   "metadata": {},
   "source": [
    "## Classes Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = dataframe['Churn'].value_counts()[0] + dataframe['Churn'].value_counts()[1]\n",
    "print(f\"Deu Churn: {dataframe['Churn'].value_counts()[0]/total}\\nNão deu Churn: {dataframe['Churn'].value_counts()[1]/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007d76b",
   "metadata": {},
   "source": [
    "## Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='skew.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db14a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop(columns=['Gender','Subscription Type', 'Contract Length']).skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381fcac",
   "metadata": {},
   "source": [
    "## Outliers Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc94432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "print('===Age===')\n",
    "print(f'Mean between max e min: {(dataframe[\"Age\"].max()+dataframe[\"Age\"].min())/2}')\n",
    "print(f'All values mean: {round(dataframe[\"Age\"].mean(),2)}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Tenure\n",
    "print('===Tenure===')\n",
    "print(f'Mean between max e min: {(dataframe[\"Tenure\"].max()+dataframe[\"Tenure\"].min())/2}')\n",
    "print(f'All values mean: {round(dataframe[\"Tenure\"].mean(),2)}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Usage Frequency\n",
    "print('===Usage Frequency===')\n",
    "print(f'Mean between max e min: {(dataframe[\"Usage Frequency\"].max()+dataframe[\"Usage Frequency\"].min())/2}')\n",
    "print(f'All values mean: {round(dataframe[\"Usage Frequency\"].mean(),2)}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Support Calls\n",
    "print('===Support Calls===')\n",
    "print(f'Mean between max e min: {(dataframe[\"Support Calls\"].max()+dataframe[\"Support Calls\"].min())/2}')\n",
    "print(f'All values mean: {round(dataframe[\"Support Calls\"].mean(),2)}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Payment Delay\n",
    "print('===Payment Delay===')\n",
    "print(f'Mean between max e min: {(dataframe[\"Payment Delay\"].max()+dataframe[\"Payment Delay\"].min())/2}')\n",
    "print(f'All values mean: {round(dataframe[\"Payment Delay\"].mean(),2)}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Total Spend\n",
    "print('===Total Spend===')\n",
    "print(f'Mean between max e min: {(dataframe[\"Total Spend\"].max()+dataframe[\"Total Spend\"].min())/2}')\n",
    "print(f'All values mean: {round(dataframe[\"Total Spend\"].mean(),2)}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Last Interaction\n",
    "print('===Last Interaction===')\n",
    "print(f'Mean between max e min: {(dataframe[\"Last Interaction\"].max()+dataframe[\"Last Interaction\"].min())/2}')\n",
    "print(f'All values mean: {round(dataframe[\"Last Interaction\"].mean(),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba682e",
   "metadata": {},
   "source": [
    "### p.s. - the means about all the values are not so distant to the mean between the min and max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f516b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='boxplot.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ffd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoxPlot\n",
    "\n",
    "subplot_titles = list(dataframe.columns.drop(['CustomerID','Churn','Last Interaction']))\n",
    "subplot_titles.append('')\n",
    "subplot_titles.append('Last Interaction')\n",
    "subplot_titles.append('')\n",
    "\n",
    "fig = make_subplots(rows=4, \n",
    "                    cols=3, \n",
    "                    specs=[[{'type':'xy'},{'type':'xy'},{'type':'xy'}],\n",
    "                           [{'type':'xy'},{'type':'xy'},{'type':'xy'}],\n",
    "                           [{'type':'xy'},{'type':'xy'},{'type':'xy'}],\n",
    "                           [{'type':'xy'},{'type':'xy'},{'type':'xy'}]],\n",
    "                    subplot_titles=subplot_titles)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Age']),\n",
    "    row=1,col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Gender']),\n",
    "    row=1,col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Tenure']),\n",
    "    row=1,col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Usage Frequency']),\n",
    "    row=2,col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Support Calls']),\n",
    "    row=2,col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Payment Delay']),\n",
    "    row=2,col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Subscription Type']),\n",
    "    row=3,col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Contract Length']),\n",
    "    row=3,col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Total Spend']),\n",
    "    row=3,col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=dataframe['Last Interaction']),\n",
    "    row=4,col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=1000,\n",
    "                  width=1000,\n",
    "                  title_text='Distributions about the Atributes',\n",
    "                  font_color='white',\n",
    "                  paper_bgcolor='black',\n",
    "                  showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c668e63",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_numeric = dataframe.select_dtypes(['float64'])\n",
    "\n",
    "corr = dataframe_numeric.corr()\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(corr, mask=mask, cmap='mako', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b5ba8",
   "metadata": {},
   "source": [
    "### Some conclusions\n",
    "\n",
    "- CustomerID has to be removed, because it has no a priori correlation with the churn atribute\n",
    "- Tenure and Usage Frequency can be removed before a machine learning model training, because of the small correlation with the churn classification\n",
    "- Support Calls and Payment Delay, respectively, has the majors correlation with churn atribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07539351",
   "metadata": {},
   "source": [
    "## Numeric Atributes Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb122483",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aaf58b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "subplot_titles = ['Support Calls', 'Total Spend', 'Payment Delay', 'Age', 'Last Interaction']\n",
    "\n",
    "fig = make_subplots(rows=2, \n",
    "                    cols=3, \n",
    "                    specs=[[{'type':'xy'},{'type':'xy'},{'type':'xy'}],\n",
    "                           [{'type':'xy'},{'type':'xy'},{'type':'xy'}]],\n",
    "                    subplot_titles=subplot_titles)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=dataframe['Support Calls']),\n",
    "    row=1,col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=dataframe['Total Spend']),\n",
    "    row=1,col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=dataframe['Payment Delay']),\n",
    "    row=1,col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=dataframe['Age']),\n",
    "    row=2,col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=dataframe['Last Interaction']),\n",
    "    row=2,col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=1000,\n",
    "                  width=1000,\n",
    "                  title_text='Análise Univariada',\n",
    "                  font_color='white',\n",
    "                  paper_bgcolor='black',\n",
    "                  showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b94773",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- 4 out of 5 distributions are assimetric.\n",
    "- The asymmetry offsets the mean.\n",
    "- The asymmetry won't cause a desbalance training the models, because has some of equality in this asymmetrys distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7316a036",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27288b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "fig.suptitle('Análise Bivariada')\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.8)\n",
    "ax = fig.add_subplot(2,3,1) #número de linhas | número de colunas | índice do subplot\n",
    "sns.histplot(x=dataframe['Support Calls'],hue=dataframe['Churn'])\n",
    "ax.set_title('Support Calls')\n",
    "ax = fig.add_subplot(2,3,2)\n",
    "sns.histplot(x=dataframe['Total Spend'],hue=dataframe['Churn'])\n",
    "ax.set_title('Total Spend')\n",
    "ax = fig.add_subplot(2,3,3)\n",
    "sns.histplot(x=dataframe['Payment Delay'],hue=dataframe['Churn'])\n",
    "ax.set_title('Payment Delay')\n",
    "ax = fig.add_subplot(2,3,4)\n",
    "sns.histplot(x=dataframe['Age'],hue=dataframe['Churn'])\n",
    "ax.set_title('Age')\n",
    "ax = fig.add_subplot(2,3,5)\n",
    "sns.histplot(x=dataframe['Last Interaction'],hue=dataframe['Churn'])\n",
    "ax.set_title('Last Interaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe7b6f2",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "#### Support Calls\n",
    "\n",
    "- More the support calls, less the probabilty of the customer to churn.\n",
    "- More support calls can be related with difficulties and insatisfaction about the product, so it leads to churn.\n",
    "\n",
    "#### Total Spend\n",
    "\n",
    "- More the total spend of the customer with the campony, more the probability to not churn.\n",
    "- Attention: there are two different types of customer, those who buy expensive services and others who buy a lot of cheap services.\n",
    "\n",
    "\n",
    "#### Payment Delay\n",
    "\n",
    "- Less the delay of the customer payment, less the probability to churn.\n",
    "- Maybe this company gives benefits for those who pay the bills on time.\n",
    "\n",
    "#### Age\n",
    "\n",
    "- More the age of the customer, more the probability to churn.\n",
    "- Maybe older people have not enough patience to find difficulties with services.\n",
    "\n",
    "#### Last Interaction\n",
    "\n",
    "- More distant the last contact between the company and the client, more the probability to churn.\n",
    "- Maybe the company has to contact those clients with a bigger distant in time of contact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c7c2b",
   "metadata": {},
   "source": [
    "## Categorical Atributes Analysis - Gender, Subscription Type and Contract Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053b10c",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd837907",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette('pastel')[0:2]\n",
    "plt.title('Gender')\n",
    "plt.pie(dataframe['Gender'].value_counts(), labels = ['Male','Female'], colors = colors, autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma\n",
    "\n",
    "px.histogram(dataframe,x='Gender',color='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38832e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_female = dataframe[dataframe['Gender']=='Female'].shape[0]\n",
    "total_male = dataframe[dataframe['Gender']=='Male'].shape[0]\n",
    "\n",
    "female_churn = dataframe[(dataframe['Churn']==1) & (dataframe['Gender']=='Female')].shape[0]\n",
    "male_churn = dataframe[(dataframe['Churn']==0) & (dataframe['Gender']=='Male')].shape[0]\n",
    "\n",
    "print(f'Woman who churn out of total women: {(female_churn/total_female)*100}')\n",
    "print(f'Man who churn out of total men: {(male_churn/total_male)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2120109",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[(dataframe['Churn']==1)].groupby('Gender').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6a340",
   "metadata": {},
   "source": [
    "## Subscription Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Subscription Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b06ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette('pastel')[0:3]\n",
    "plt.title('Subscription Type')\n",
    "plt.pie(dataframe['Subscription Type'].value_counts(), labels = ['Standard','Premium','Basic'], colors = colors, autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "px.histogram(dataframe,x='Subscription Type',color='Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b77a6",
   "metadata": {},
   "source": [
    "## Contract Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Contract Length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c13700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart\n",
    "\n",
    "colors = sns.color_palette('pastel')[0:3]\n",
    "plt.title('Contract Length')\n",
    "plt.pie(dataframe['Contract Length'].value_counts(), labels = ['Annual','Quarterly','Monthly'], colors = colors, autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "px.histogram(dataframe,x='Contract Length',color='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9074349",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_and_churn = dataframe[(dataframe['Contract Length']=='Monthly') & (dataframe['Churn']==1)].value_counts().sum()\n",
    "monthly_and_not_churn = dataframe[(dataframe['Contract Length']=='Monthly') & (dataframe['Churn']==0)].value_counts().sum()\n",
    "print(f'Total of tuples:{dataframe.shape[0]}')\n",
    "print(f'Monthly Subscription Type and Churn:{monthly_and_churn}')\n",
    "print(f'Monthly Subscription Type and Not Churn:{monthly_and_not_churn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f32d6a",
   "metadata": {},
   "source": [
    "### Some conclusions\n",
    "\n",
    "- Proportionally, women churn more than men.\n",
    "- The subscription type has no different values for a person who churn or not, has no apparently relation.\n",
    "- Those who subscribe for a monthly plan always churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b748e",
   "metadata": {},
   "source": [
    "## Conclusions about the Exploratory Data Analysis\n",
    "- Are not necessary to use these columns to train machine learning models: CustomerID, Tenure, Usage Frequency and maybe Subscription Type.\n",
    "- Caracteristics like Female Gender, age above 60, more support calls, big distance in contact with the company, small spending with services and delay tend to the customer churn.\n",
    "- Customers with Monthly Subscryption Type always churn.\n",
    "- The dataset has a good distribution about the two classes (churn and not churn), but it is interesting to use strategies to bypass the sligth difference about this classes to be as fair as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab73344e",
   "metadata": {},
   "source": [
    "## Part 2: Training Machine Learning Models to Predict Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f790b",
   "metadata": {},
   "source": [
    "## Libraries and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d20a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ff087",
   "metadata": {},
   "source": [
    "## Remove the Columns and Separate the Dataset (60,20,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe3cff",
   "metadata": {},
   "source": [
    "In this case, there is one dataset for training and other for testing, so I decided just to separate the training dataset in train (70%) and validation (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1361b35-b864-4468-b9ce-814227ae8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('customer_churn_dataset-training-master.csv')\n",
    "dataframe = dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f09e3-a1a0-4fff-8299-5c0156e251c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns=['CustomerID', 'Tenure', 'Usage Frequency', 'Subscription Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ed984-2637-4d39-8820-9e52e9bb591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a4e0d-c9dd-4b2c-96b0-a7b16358b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop(columns=['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af1749-8737-4f0f-9d52-9eb039059156",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0061f-84c2-42e1-b969-1c83e0f770cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataframe['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298adf46-92af-4312-9a74-f02420408bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 70% train and 30% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe80b9b-cdec-4e89-bbfc-7e51825b7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test = pd.read_csv('customer_churn_dataset-testing-master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18f747-c514-4597-ba7e-580bda4767a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test = dataframe_test.drop(columns=['CustomerID', 'Tenure', 'Usage Frequency', 'Subscription Type']) # , 'Tenure', 'Usage Frequency', 'Subscription Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd06e01-bb16-42b3-8a40-923248d6ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = dataframe_test.drop(columns=['Churn']), dataframe_test['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f1584",
   "metadata": {},
   "source": [
    "## Ways to Bypass the Classes Distribution Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763796e-77a1-46d1-b03d-a3129a8bffa2",
   "metadata": {},
   "source": [
    "In this case I decided to not implement an estrategy to bypass the different distributions because they are very close in value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae47e6-3048-4e9a-8a5b-ab32fd1e314e",
   "metadata": {},
   "source": [
    "## Separating Numerical and Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ca3f0-4be3-4b2b-8b5f-9e35a43094ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924dd3d-913d-486f-9ea6-78fc0962d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['Age','Support Calls','Payment Delay','Total Spend','Last Interaction']\n",
    "categorical_cols = ['Gender', 'Contract Length']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465a140-4a24-4323-94f3-c921df27e697",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57210c",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054cd9b-e481-488e-90b3-6059ce10135b",
   "metadata": {},
   "source": [
    "Because there was only one line with no values for all the attributes, we just removed it from the dataset, so we don't need imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34185a",
   "metadata": {},
   "source": [
    "## Scale Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0d7651-c387-45d7-9c34-c2cda4f973f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(dataframe[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11e9cd-5c59-41a5-98d1-5e3db4cf37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numeric_cols] = scaler.transform(X_train[numeric_cols])\n",
    "X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee3724-1f73-4b3a-852d-c163c3785a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb04ee-457c-4ea9-a5a3-dca506c10f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5d4ebd",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b749409-821a-4391-a10a-724df844ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore').fit(dataframe[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65eb741-2010-4443-81a2-9549b95efb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff89c8f-b00a-46e1-8d86-97964ed8e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[encoded_cols] = encoder.transform(X_train[categorical_cols])\n",
    "X_val[encoded_cols] = encoder.transform(X_val[categorical_cols])\n",
    "X_test[encoded_cols] = encoder.transform(X_test[categorical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161aefb3-fbbd-4929-ae42-63be066f9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c23ebe-3936-47d2-a9e4-c901e81a4e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[numeric_cols + encoded_cols]\n",
    "X_val = X_val[numeric_cols + encoded_cols]\n",
    "X_test = X_test[numeric_cols + encoded_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc88e0-7a1e-4a0a-98a6-72be80d96ed9",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd303e-3612-4f54-a927-260883af2846",
   "metadata": {},
   "source": [
    "## Decision Tree - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a641d66-5346-4d5a-9acd-6976b4198726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26184d94-80b9-4145-8ef3-a9759566bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e196486-e666-407a-9439-044c0e863a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train) == len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568c99a-a0ac-4ed3-bb7a-cd0a0f5a955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0587e71-1e1b-4982-8721-1c2d0c3598e9",
   "metadata": {},
   "source": [
    "## Decision Tree - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600081e6-27f8-4727-87ed-00fc115b214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b1cfa-4f74-4d5f-ab7d-d2eb5cf2421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138a623-fe70-460a-bd70-3d1dfdb037bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(val_preds, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb1960-73c3-4b63-a751-0f62c1e895d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for validation\n",
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813a457-c24b-4422-be06-25d36590ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for test\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72b8a0-a451-4a91-96f4-623bf5ef71a8",
   "metadata": {},
   "source": [
    "## Decision Tree - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f7fad-1bce-4f0a-a696-aff4068f366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(**params):\n",
    "    model = DecisionTreeClassifier(random_state=42, **params).fit(X_train, y_train)\n",
    "    return model.score(X_train, y_train), model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a8040-c964-4cef-98e4-d3aa56a53d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning max_depth\n",
    "\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "\n",
    "range_ = 20\n",
    "\n",
    "for i in range(1, range_):\n",
    "    result = test_params(max_depth=i)\n",
    "    train_errors.append(1-result[0])\n",
    "    val_errors.append(1-result[1])\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Max Depth Tuning')\n",
    "plt.plot(range(1, range_),train_errors)\n",
    "plt.plot(range(1, range_),val_errors) \n",
    "plt.legend(['Train Error','Val Error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c160c-78cd-4e58-8a99-173b9f1dfab9",
   "metadata": {},
   "source": [
    "The validation error start to increase in max_depth > 10, so I choose this value as the best to train my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b51ee-0882-4360-ab23-eda3d8353945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning max_leaf_nodes\n",
    "\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "\n",
    "range_ = 100\n",
    "\n",
    "for i in range(2, range_):\n",
    "    result = test_params(max_leaf_nodes=i)\n",
    "    train_errors.append(1-result[0])\n",
    "    val_errors.append(1-result[1])\n",
    "    \n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Max Leaf Nodes')\n",
    "plt.plot(range(2, range_),train_errors)\n",
    "plt.plot(range(2, range_),val_errors) \n",
    "plt.legend(['Train Error','Val Error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354b5e7-3b52-4741-951d-ceac70906d28",
   "metadata": {},
   "source": [
    "This parameter does not have such a good relevance with the validation error, so a pickup the valeu 100 for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d06f34-6be7-4568-b669-7645d7f84942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Decision Tree Prediction\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=10, max_leaf_nodes=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Train: {model.score(X_train,y_train)}')\n",
    "print(f'Validation: {model.score(X_val,y_val)}')\n",
    "print(f'Test: {model.score(X_test,y_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653eaa1d-70c4-4cd6-839a-4a597ad4a611",
   "metadata": {},
   "source": [
    "### Conclusions: \n",
    "- I tried to include the other columns to see if it makes difference in the prediction rate, but nothing happens as expected, because those columns literally does not have importance to predict churn.\n",
    "- I know how a chart for hyperparameter tuning has to see, but these for decision tree are this way for some problem of insufficient categories maybe.\n",
    "- The prediction rate is low because of the high generalization of the model or the test dataset having difference intervals os values compared with the training one.\n",
    "- I've tried to see other people's works about the dataset in Kaggle but everyone else get low prediction rates for test data (every value near 50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f782f-1a80-41b2-9fa4-3ea3e6a200ff",
   "metadata": {},
   "source": [
    "## Random Forest - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6754ce-88cb-457f-8e2a-890fd655b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc346ebe-5067-4747-a143-a203ef6f9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569477bc-e227-4655-b55e-2cb66dd1194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4880dc-b817-47e7-9242-1c34d4320cd2",
   "metadata": {},
   "source": [
    "## Random Forest - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876223e-51ff-4c03-b750-7efb285f69e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108759f9-dcca-4c2e-8106-2716c0a2a5fd",
   "metadata": {},
   "source": [
    "## Random Forest - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993622d6-4dfb-49d0-aaa5-e5b263f89470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(**params):\n",
    "    model = RandomForestClassifier(random_state=42, **params).fit(X_train, y_train)\n",
    "    return model.score(X_train, y_train), model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b6cb8-5830-4c5c-a1bc-965ca07b6977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing max_estimators\n",
    "\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "\n",
    "range_ = 8\n",
    "\n",
    "for i in range(1, range_):\n",
    "    result = test_params(max_depth=i)\n",
    "    train_errors.append(1-result[0])\n",
    "    val_errors.append(1-result[1])\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Max Estimators Tuning')\n",
    "plt.plot(range(1, range_),train_errors)\n",
    "plt.plot(range(1, range_),val_errors) \n",
    "plt.legend(['Train Error','Val Error'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544cdfad-ffe1-47ec-af03-69fd1c5815bd",
   "metadata": {},
   "source": [
    "My PC doesn't have enough CPU/GPU power to tune this parameter in brute force, so I decided to pick the last value: 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0cc46b-9361-42bf-ba48-3a86fc5f1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning max_depth\n",
    "\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "\n",
    "range_ = 20\n",
    "\n",
    "for i in range(1, range_):\n",
    "    result = test_params(max_depth=i)\n",
    "    train_errors.append(1-result[0])\n",
    "    val_errors.append(1-result[1])\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Max Depth Tuning')\n",
    "plt.plot(range(1, range_),train_errors, label='Train Error')\n",
    "plt.plot(range(1, range_),val_errors, label='Val Error') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8592bf-bf70-48a4-a408-6553308a46cf",
   "metadata": {},
   "source": [
    "We can see that over value 16 the max_depth for a Random Forest begins to increase the validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315d43a-6df3-4726-ae69-f513b4e94a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Random Forest Prediction\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=7, max_depth=16, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Train: {model.score(X_train,y_train)}')\n",
    "print(f'Validation: {model.score(X_val,y_val)}')\n",
    "print(f'Test: {model.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc29d7-8d9a-49ad-bf05-95f7ac850b62",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "- Random Forests are so much complex to tune hyperparameters because of its computacional complexity.\n",
    "- Similar to the Decision Tree this model had a bad performance with the test dataset.\n",
    "- Maybe the test dataset provided by the authors on kaggle are too much different in values than the training one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e775a",
   "metadata": {},
   "source": [
    "## Compare the Model with a Dummy One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3f5ba-30fe-4739-966e-d8a6d41b1a12",
   "metadata": {},
   "source": [
    "Using a Dummy Model we can see if a model it's really good to predict something. We analyze if choosing randomly numbers can beat the predictions of the model and prove that the model prediction is not good at all or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eefbfe-3b34-466a-a1fd-10d3326630ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "number_correct = 0\n",
    "number_incorrect = 0\n",
    "\n",
    "for pred in y_test:\n",
    "    if random.randint(0, 1) == pred:\n",
    "        number_correct += 1\n",
    "    else:\n",
    "        number_incorrect += 1\n",
    "\n",
    "print(f'Dummy Model Accuracy: {number_correct/(number_correct+number_incorrect)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad4161-3e5b-4bce-a81c-6da7426c7fbe",
   "metadata": {},
   "source": [
    "Comparing to the best model (Decision Tree) we see that the dummy is lightly worst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d38a3-cfb7-45cc-bd90-f2eea2d23b11",
   "metadata": {},
   "source": [
    "## Final Conclusion\n",
    "\n",
    "- These predictions are a little greater than 50%.\n",
    "- They are not the ideal one, but can be useful when you don't have tools to predict churn in the company, and you have to avoid churn.\n",
    "- The predicitions values are low maybe because of some points: 1. Insufficient attributes to colaborate with the prediction 2. Test dataset extremely different in values with the training one (in case of patterns and how data correlate with itself).\n",
    "- Overall this predictions could be used for some initial operation to predict churn for this company related with the dataset, because it is ligthly better than a dummy one, but it would be necessary to see again the datasets and it's values, distributions, patterns, etc. to improve the data used to train the model and get better results.\n",
    "- With more attributes or different test datasets (one with the same pattern as the training one, sfor example with people who paid for monthly services always churn) we may have better results.\n",
    "- No one in kaggle had great results using classic machine learning models, just one guy had a little increase to 54% of accuraccy using a deep neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
